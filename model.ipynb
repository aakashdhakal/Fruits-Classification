{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Tensorflow libs\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training and testing directories\n",
    "base_dir = './fruits/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the training directory exists\n",
    "if not os.path.exists(base_dir):\n",
    "    raise Exception(f\"Base directory {base_dir} does not exist.\")\n",
    "elif not os.path.exists(train_dir):\n",
    "    raise Exception(f\"Training directory {train_dir} does not exist.\")\n",
    "elif not os.path.exists(test_dir):\n",
    "    raise Exception(f\"Testing directory {test_dir} does not exist.\")\n",
    "else:\n",
    "    print(\"All directories exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Using GPU: {gpus}\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through subdirectories of the training directory to check for corrupted images\n",
    "for subdir in os.listdir(train_dir):\n",
    "    subdir_path = os.path.join(train_dir, subdir)\n",
    "    \n",
    "    if not os.path.isdir(subdir_path):  # Skip if not a directory\n",
    "        continue\n",
    "\n",
    "    image_count = 0  # Track valid images\n",
    "\n",
    "    # Iterate files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        file_path = os.path.join(subdir_path, filename)\n",
    "\n",
    "        # Check if the file is an image\n",
    "        if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            print(f\"Skipping {file_path} due to invalid file extension\")\n",
    "            continue\n",
    "\n",
    "        # Check if the image is corrupted or has transparency issues\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # Handle transparent images\n",
    "                if img.mode == 'RGBA':\n",
    "                    img = img.convert('RGB')\n",
    "                    img.save(file_path)  # Save after conversion\n",
    "\n",
    "                img.verify()  # Verify image integrity\n",
    "\n",
    "            image_count += 1  # Increase count for valid images\n",
    "\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print(f\"Deleting corrupted file {file_path}: {e}\")\n",
    "            os.remove(file_path)\n",
    "\n",
    "    # Print the number of valid images in each class directory\n",
    "    print(f\"Number of valid images in {subdir}: {image_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images in each class within the training directory\n",
    "class_counts = {}\n",
    "for subdir in os.listdir(train_dir):\n",
    "\tsubdir_path = os.path.join(train_dir, subdir)\n",
    "\tif os.path.isdir(subdir_path):\n",
    "\t\tnum_images = len([name for name in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, name))])\n",
    "\t\tclass_counts[subdir] = num_images\n",
    "\n",
    "# Extract class names and their corresponding image counts\n",
    "class_names = sorted(list(class_counts.keys()))\n",
    "image_counts = list(class_counts.values())\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(7, 10))\n",
    "plt.barh(class_names, image_counts, color='red')\n",
    "plt.xlabel('Number of Images')\n",
    "plt.ylabel('Class Names')\n",
    "plt.title('Number of Images in Each Class within the Training Directory')\n",
    "plt.show()\n",
    "\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 100\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "classes = os.listdir(train_dir)[:12]  # Limit to 12 classes\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    file_name = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][0]\n",
    "    img_path = os.path.join(class_dir, file_name)\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_name)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = train_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Specify the validation split\n",
    ")\n",
    "\n",
    "val_dataset = val_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # Specify the subset as validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "# If model is not available, create a new model\n",
    "if os.path.exists('fruits_classification.keras'):\n",
    "    model = tf.keras.models.load_model('fruits_classification.keras')\n",
    "    print(\"Model loaded.\")\n",
    "else:\n",
    "    # Model architecture \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        \n",
    "        tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch and validation steps\n",
    "\n",
    "steps_per_epoch = train_dataset.samples // train_dataset.batch_size\n",
    "validation_steps = val_dataset.samples // val_dataset.batch_size\n",
    "\n",
    "steps_per_epoch, validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('fruits_classification.keras', save_best_only=True)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduceLearningRate = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using the Adam optimizer and categorical cross entropy-loss function\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1), optimizer=tf.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.Precision()])\n",
    "\n",
    "# Training the model using the CallbackAcc object and storing the history of the model\n",
    "history = model.fit(\n",
    "    train_dataset, # Train the model on the augmented training images\n",
    "    steps_per_epoch=steps_per_epoch,   # Number of steps (batches) to yield from the generator at each epoch\n",
    "    validation_steps=validation_steps,   # Number of steps (batches) to yield from the generator at each epoch\n",
    "    epochs=10,    # Number of epochs to train the model\n",
    "    validation_data=val_dataset,    # Validate the model on the augmented validation images\n",
    "    verbose=1,    # Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "    callbacks=[checkpoint, earlyStopping, reduceLearningRate]    # Callback function to stop training if accuracy is greater than or equal to 99%\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss', linestyle='dashed')   \n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_acc) + 1), train_acc, label='Training Accuracy', linestyle='dashed')\n",
    "plt.plot(range(1, len(val_acc) + 1), val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_images_structured(directory, target_size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    images = []  # Initialize an empty list to store images\n",
    "    labels = []  # Initialize an empty list to store labels\n",
    "    class_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]  # Get all subdirectories in the directory\n",
    "    for class_dir in class_dirs:  # Iterate over each class directory\n",
    "        class_path = os.path.join(directory, class_dir)  # Get the full path of the class directory\n",
    "        for filename in os.listdir(class_path):  # Iterate over each file in the class directory\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Check if the file is an image\n",
    "                img_path = os.path.join(class_path, filename)  # Get the full path of the image file\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)  # Load the image with the specified target size\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)  # Convert the image to an array\n",
    "                img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to create a batch axis\n",
    "                images.append(img_array)  # Append the image array to the images list\n",
    "                labels.append(class_dir)  # Append the class label to the labels list\n",
    "    return np.vstack(images), labels  # Return the stacked images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images, test_labels = load_test_images_structured(test_dir)\n",
    "\n",
    "# Normalize the test images\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Predict the classes of the test images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Get the predicted class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print the class indices from training\n",
    "print(\"Class Indices from Training:\", class_names)\n",
    "\n",
    "# Adjust test labels to lowercase\n",
    "adjusted_test_labels = [label.lower() for label in test_labels]\n",
    "\n",
    "# Create a label map from class names to indices\n",
    "label_map = {name.lower(): idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# Map true class labels to their corresponding indices\n",
    "true_classes = [label_map[label] for label in adjusted_test_labels]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes, labels=list(label_map.values()))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true_classes, predicted_classes, labels=list(label_map.values()), zero_division=0))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(100, 100))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Rescale\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get random 10 images from dir\n",
    "random_images = random.sample(os.listdir('./fruits/predict/'), 10)\n",
    "actual_labels = [img.split('_')[0] for img in random_images]\n",
    "plt.figure(figsize=(10, 20))\n",
    "for i, img in enumerate(random_images):\n",
    "    img_path = os.path.join('./fruits/predict/', img)\n",
    "    predicted_class, confidence = predict_image(img_path)\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Actual: {actual_labels[i]}\\nPredicted: {predicted_class}\\nConf: {confidence:.2f}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_according_to_fruit = {\n",
    "    \"apple\": (0, 0, 255),       # Red\n",
    "    \"avocado\": (0, 255, 0),     # Green\n",
    "    \"banana\": (0, 255, 255),    # Yellow\n",
    "    \"blueberry\": (255, 0, 0),   # Blue\n",
    "    \"cherry\": (0, 0, 255),      # Red\n",
    "    \"grape\": (128, 0, 128),     # Purple\n",
    "    \"kiwi\": (0, 255, 0),        # Green\n",
    "    \"mango\": (0, 165, 255),     # Orange\n",
    "    \"orange\": (0, 165, 255),    # Orange\n",
    "    \"pear\": (0, 255, 255),      # Yellow\n",
    "    \"pineapple\": (0, 255, 255), # Yellow\n",
    "    \"pomegranate\": (0, 0, 255), # Red\n",
    "    \"raspberry\": (0, 0, 255),   # Red\n",
    "    \"strawberry\": (0, 0, 255),  # Red\n",
    "    \"watermelon\": (0, 255, 0),  # Green\n",
    "    \"dragonfruit\": (0, 0, 255), # Red\n",
    "    \"guava\": (0, 255, 0),       # Green\n",
    "    \"lychee\": (0, 0, 255),      # Red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow('Fruit Classification', frame)\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "# # Preprocess the frame\n",
    "#     img = cv2.resize(frame, (150, 150))  # Resize to match model input\n",
    "#     img = img.astype(\"float32\") / 255.0  # Normalize\n",
    "#     img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# # Make prediction\n",
    "#     predictions = model.predict(img)\n",
    "#     predicted_class = np.argmax(predictions)\n",
    "#     predicted_label = class_names[predicted_class]\n",
    "#     confidence = np.max(predictions) * 100  # Convert to percentage\n",
    "    \n",
    "#     # Display result on frame\n",
    "#     text = f\"{predicted_label}: {confidence:.2f}%\"\n",
    "#     cv2.putText(frame, text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#     cv2.imshow(\"Fruit Classification\", frame)\n",
    "#      # Exit when 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release resources\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
